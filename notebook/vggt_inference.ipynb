{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1d53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'vggt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408e402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuqin/miniconda3/envs/vggt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5ee2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:4, dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:4\" if torch.cuda.is_available() else \"cpu\"\n",
    "# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+)\n",
    "dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n",
    "print(f\"Using device: {device}, dtype: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e67cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and load the pretrained weights.\n",
    "# This will automatically download the model weights the first time it's run, which may take a while.\n",
    "model = VGGT.from_pretrained(\"../checkpoint/models--facebook--VGGT-1B/snapshots/860abec7937da0a4c03c41d3c269c366e82abdf9\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a316eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../vggt/examples/kitchen/images/02.png', '../vggt/examples/kitchen/images/13.png', '../vggt/examples/kitchen/images/18.png', '../vggt/examples/kitchen/images/01.png', '../vggt/examples/kitchen/images/00.png']\n"
     ]
    }
   ],
   "source": [
    "# 列出 vggt/examples/kitchen/images 的所有png图片，并保存其路径到 image_names 列表中\n",
    "image_names = [\n",
    "    os.path.join(\"../vggt/examples/kitchen/images\", f)\n",
    "    for f in os.listdir(\"../vggt/examples/kitchen/images\")\n",
    "    if f.endswith(\".png\")\n",
    "]\n",
    "print(image_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc31447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 350, 518])\n"
     ]
    }
   ],
   "source": [
    "images = load_and_preprocess_images(image_names).to(device)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15ee096",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(dtype=dtype):\n",
    "        # Predict attributes including cameras, depth maps, and point maps.\n",
    "        predictions = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e876dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pose_enc', 'pose_enc_list', 'depth', 'depth_conf', 'world_points', 'world_points_conf'])\n"
     ]
    }
   ],
   "source": [
    "print(predictions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc77daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25, 9])\n",
      "4 torch.Size([1, 25, 9])\n"
     ]
    }
   ],
   "source": [
    "# camera parameters\n",
    "print(predictions['pose_enc'].shape)\n",
    "print(len(predictions['pose_enc_list']), predictions['pose_enc_list'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25, 350, 518, 1]) [0.31, 4.11]\n",
      "torch.Size([1, 25, 350, 518]) 1.00, 33.47]\n"
     ]
    }
   ],
   "source": [
    "# depth map, conf 为 aleatoric uncertainty\n",
    "print(predictions['depth'].shape, f\"[{predictions['depth'].min().item():.2f}, {predictions['depth'].max().item():.2f}]\")print(predictions['depth_conf'].shape, f\"{predictions['depth_conf'].min().item():.2f}, {predictions['depth_conf'].max().item():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a5e2935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25, 350, 518, 3])\n",
      "torch.Size([1, 25, 350, 518]) [1.00, 32.37]\n"
     ]
    }
   ],
   "source": [
    "# point map\n",
    "print(predictions['world_points'].shape)\n",
    "print(predictions['world_points_conf'].shape, f\"[{predictions['world_points_conf'].min().item():.2f}, {predictions['world_points_conf'].max().item():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vggt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
